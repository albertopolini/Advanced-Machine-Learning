{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "some_regularization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertopolini/Advanced-Machine-Learning/blob/main/some_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG16KcmYALhG"
      },
      "source": [
        "# Fully Connected Feed-Forward Network\n",
        "\n",
        "In this notebook we will play with Feed-Forward FC-NN (Fully Connected Neural Network) for a *classification task*: \n",
        "\n",
        "Image Classification on MNIST Dataset\n",
        "\n",
        "**RECALL**\n",
        "\n",
        "In the FC-NN, the output of each layer is computed using the activations from the previous one, as follows:\n",
        "\n",
        "$$h_{i} = \\sigma(W_i h_{i-1} + b_i)$$\n",
        "\n",
        "where ${h}_i$ is the activation vector from the $i$-th layer (or the input data for $i=0$), ${W}_i$ and ${b}_i$ are the weight matrix and the bias vector for the $i$-th layer, respectively. \n",
        "<br><rb>\n",
        "$\\sigma(\\cdot)$ is the activation function. In our example, we will use the *ReLU* activation function for the hidden layers and *softmax* for the last layer.\n",
        "\n",
        "Our loss function will be the **categorical crossentropy**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YySfiTRCiat5"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cpVZVFIALhK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.backend import abs, sum\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aY27siWALhk"
      },
      "source": [
        "## Data preparation (`keras.dataset`)\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of $60,000$ examples and a test set of $10,000$ examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf. [arXiv:1708.07747](http://arxiv.org/abs/1708.07747)**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/758/1*cd0yDlTocSud8W-nT308PQ.png\" width=\"80%\" />\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://hanxiao.github.io/2017/08/26/Fashion-MNIST-a-Drop-In-Replacement-of-MNIST-for-Benchmarking-Machine-Learning-Algorithms/embedding.gif\" width=\"80%\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_HVdNfgaP5A"
      },
      "source": [
        "Since this dataset is **provided** with Keras, we just ask the `keras.dataset` model for training and test data.\n",
        "\n",
        "We will:\n",
        "\n",
        "* download the data\n",
        "* reshape data to be in vectorial form (original data are images)\n",
        "* normalize between 0 and 1.\n",
        "\n",
        "The `categorical_crossentropy` loss expects a **one-hot-vector** as input, therefore we apply the `to_categorical` function from `keras.utilis` to convert integer labels to **one-hot-vectors**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3reWqLtALhl"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95KM6c43ALhp",
        "outputId": "e43b7921-3ccc-48ef-9566-86d5fcfe83c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrHXczGHlmDX",
        "outputId": "82f1c5c3-226a-42bb-829c-d986c6c8106f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFDaI9Hs-CPF",
        "outputId": "576913f8-f046-46d5-f129-d332052df37f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Number of categories:',len(set(y_train)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GeCi5_9ALhv"
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype(\"float32\")\n",
        "X_test = X_test.astype(\"float32\")\n",
        "\n",
        "# Put everything on grayscale (normalization)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "#\n",
        "## convert class vectors to binary class matrices (one hot encode). \n",
        "#They are already numbers so you can use the function directly to_categorical\n",
        "Y_train =  np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEyLRLaBBiDK",
        "outputId": "bb8c4e95-6355-4826-fcc3-0165bdb883e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y_train, y_train"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              " array([9, 0, 0, ..., 3, 0, 5], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_fCwONCALhz"
      },
      "source": [
        "#### Split Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxe5WJdoALh1"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz3Jct-SALiA",
        "outputId": "95dedefd-d022-468e-904d-ff1061a10d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Size of the train set:', X_train.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the train set: (45000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8sPlMAoALiF",
        "outputId": "9ad0fd81-b3b3-4c35-c956-d6e3a646a39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# Display data as an image on a 2D regular raster.\n",
        "# The input may either be actual RGB(A) data, or 2D scalar data,\n",
        "# which will be rendered as a pseudocolor image\n",
        "\n",
        "plt.imshow(X_train[6].reshape(28, 28))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f386959b790>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_etarmsaALiJ",
        "outputId": "6ec850cb-284e-4714-eb2d-2f3ac9692be4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(np.asarray(range(10)))\n",
        "print(Y_train[6].astype('int'))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[0 0 0 0 0 1 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUa0gVqTALiO",
        "outputId": "e245bdaf-876d-4ea4-ae56-cdcd188b8b8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(X_val[0].reshape(28, 28))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f38695c52d0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6s_OQPeALiT",
        "outputId": "b7c80a55-6bf3-464e-e3de-b003c85ddb7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(np.asarray(range(10)))\n",
        "print(Y_val[0].astype('int'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n",
            "[0 0 0 0 0 0 0 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjw-jEmFALhI"
      },
      "source": [
        "## Model definition\n",
        "\n",
        "In our case we build a Sequential model with five [Dense](http://keras.io/layers/core/#dense) (aka fully connected) layers. Notice that the output layer has the softmax activation function. \n",
        "\n",
        "The resulting model is actually a `function` of its own inputs implemented using the Keras backend. \n",
        "\n",
        "We apply the categorical crossentropy loss and choose SGD as the optimizer. \n",
        "\n",
        "Please remind that Keras supports a variety of different [optimizers](http://keras.io/optimizers/) and [loss functions](http://keras.io/objectives/), which you may want to check out. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hyVyDDAALiY"
      },
      "source": [
        "## Training\n",
        "Having defined and compiled the model, it can be trained using the `fit` function. We also specify a validation dataset to monitor validation loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jOa9rMbALhV",
        "outputId": "41893cdb-40d2-44f0-f664-97736450d767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dims = X_train.shape[1]\n",
        "\n",
        "nb_classes = 10\n",
        "\n",
        "#\"advanced\" usage -- a possible way to initialize weights ..> https://keras.io/api/layers/initializers/\n",
        "initializer = tf.keras.initializers.GlorotUniform(seed=1234) \n",
        "\n",
        "# BUILD\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(dims,), activation = \"relu\", kernel_initializer=initializer))\n",
        "model.add(Dense(256, activation = \"relu\", kernel_initializer=initializer))\n",
        "model.add(Dense(32, activation = \"relu\", kernel_initializer=initializer))\n",
        "model.add(Dense(16, activation = \"relu\", kernel_initializer=initializer))\n",
        "model.add(Dense(nb_classes, activation = \"softmax\", kernel_initializer=initializer))\n",
        "\n",
        "\n",
        "# COMPILE --> optimization details\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD # yet another way to set up optimizers explicitly --> https://keras.io/api/optimizers/\n",
        "model.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Rv7wSfALjc",
        "outputId": "8924a772-f5c4-4a14-db65-b9335cd206c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We already used `summary`\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                8224      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 542,170\n",
            "Trainable params: 542,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJUqfP1EALib",
        "scrolled": false,
        "outputId": "c7cd635a-6132-4bc9-a473-df42934216ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#train! --> notice the validation steps\n",
        "\n",
        "n_epochs =20\n",
        "network_history = model.fit(X_train, Y_train, batch_size=128, \n",
        "                            epochs=n_epochs, verbose=2, validation_data=(X_val, Y_val))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "352/352 - 2s - loss: 2.1969 - accuracy: 0.2925 - val_loss: 2.0995 - val_accuracy: 0.3909\n",
            "Epoch 2/20\n",
            "352/352 - 1s - loss: 2.0145 - accuracy: 0.4178 - val_loss: 1.9309 - val_accuracy: 0.4304\n",
            "Epoch 3/20\n",
            "352/352 - 1s - loss: 1.8422 - accuracy: 0.4449 - val_loss: 1.7533 - val_accuracy: 0.4566\n",
            "Epoch 4/20\n",
            "352/352 - 1s - loss: 1.6546 - accuracy: 0.4782 - val_loss: 1.5605 - val_accuracy: 0.5038\n",
            "Epoch 5/20\n",
            "352/352 - 1s - loss: 1.4629 - accuracy: 0.5271 - val_loss: 1.3727 - val_accuracy: 0.5535\n",
            "Epoch 6/20\n",
            "352/352 - 1s - loss: 1.2797 - accuracy: 0.5932 - val_loss: 1.1966 - val_accuracy: 0.6220\n",
            "Epoch 7/20\n",
            "352/352 - 1s - loss: 1.1192 - accuracy: 0.6441 - val_loss: 1.0535 - val_accuracy: 0.6595\n",
            "Epoch 8/20\n",
            "352/352 - 1s - loss: 0.9972 - accuracy: 0.6741 - val_loss: 0.9503 - val_accuracy: 0.6843\n",
            "Epoch 9/20\n",
            "352/352 - 1s - loss: 0.9106 - accuracy: 0.6959 - val_loss: 0.8773 - val_accuracy: 0.7043\n",
            "Epoch 10/20\n",
            "352/352 - 1s - loss: 0.8478 - accuracy: 0.7150 - val_loss: 0.8228 - val_accuracy: 0.7204\n",
            "Epoch 11/20\n",
            "352/352 - 1s - loss: 0.8008 - accuracy: 0.7288 - val_loss: 0.7829 - val_accuracy: 0.7273\n",
            "Epoch 12/20\n",
            "352/352 - 1s - loss: 0.7648 - accuracy: 0.7396 - val_loss: 0.7500 - val_accuracy: 0.7405\n",
            "Epoch 13/20\n",
            "352/352 - 1s - loss: 0.7356 - accuracy: 0.7512 - val_loss: 0.7234 - val_accuracy: 0.7503\n",
            "Epoch 14/20\n",
            "352/352 - 1s - loss: 0.7113 - accuracy: 0.7594 - val_loss: 0.7012 - val_accuracy: 0.7589\n",
            "Epoch 15/20\n",
            "352/352 - 1s - loss: 0.6899 - accuracy: 0.7670 - val_loss: 0.6812 - val_accuracy: 0.7675\n",
            "Epoch 16/20\n",
            "352/352 - 1s - loss: 0.6711 - accuracy: 0.7753 - val_loss: 0.6635 - val_accuracy: 0.7738\n",
            "Epoch 17/20\n",
            "352/352 - 1s - loss: 0.6541 - accuracy: 0.7807 - val_loss: 0.6488 - val_accuracy: 0.7808\n",
            "Epoch 18/20\n",
            "352/352 - 1s - loss: 0.6386 - accuracy: 0.7860 - val_loss: 0.6340 - val_accuracy: 0.7853\n",
            "Epoch 19/20\n",
            "352/352 - 1s - loss: 0.6248 - accuracy: 0.7909 - val_loss: 0.6205 - val_accuracy: 0.7912\n",
            "Epoch 20/20\n",
            "352/352 - 2s - loss: 0.6120 - accuracy: 0.7960 - val_loss: 0.6085 - val_accuracy: 0.7958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw7hl-VJALig"
      },
      "source": [
        "### Plotting Network Performance Trend\n",
        "The return value of the `fit` function is a `keras.callbacks.History` object which contains the entire history of training/validation loss and accuracy, for each epoch. We can therefore plot the behaviour of loss and accuracy during the training phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMnowu6DALih",
        "outputId": "31185e76-7d99-46dd-c3c3-ddc4fab11de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "x_plot = list(range(1,n_epochs+1))\n",
        "\n",
        "def plot_history(network_history):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(x_plot, network_history.history['loss'])\n",
        "    plt.plot(x_plot, network_history.history['val_loss'])\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.plot(x_plot, network_history.history['accuracy'])\n",
        "    plt.plot(x_plot, network_history.history['val_accuracy'])\n",
        "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(network_history)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV6yD1wJALir"
      },
      "source": [
        "After `20` epochs, we get a `~80%` validation accuracy.\n",
        "\n",
        "* If you increase the number of epochs, you will get definitely better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ_R00XXALja"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf65svAHALjb"
      },
      "source": [
        "# Inspecting Layers\n",
        "\n",
        "not essential, but will use this to check the regularization effects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_NO8BcALjh",
        "outputId": "8a5b36df-d1df-4787-ce53-42c5f28ddff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Model Input Tensors: ', model.input, end='\\n\\n')\n",
        "print('Layers - Network Configuration:', end='\\n\\n')\n",
        "for layer in model.layers:\n",
        "    print(layer.name, layer.trainable)\n",
        "    print('Layer Configuration:')\n",
        "    print(layer.get_config(), end='\\n{}\\n'.format('----'*10))\n",
        "print('Model Output Tensors: ', model.output)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Input Tensors:  KerasTensor(type_spec=TensorSpec(shape=(None, 784), dtype=tf.float32, name='dense_5_input'), name='dense_5_input', description=\"created by layer 'dense_5_input'\")\n",
            "\n",
            "Layers - Network Configuration:\n",
            "\n",
            "dense_5 True\n",
            "Layer Configuration:\n",
            "{'name': 'dense_5', 'trainable': True, 'batch_input_shape': (None, 784), 'dtype': 'float32', 'units': 512, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': 1234}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "----------------------------------------\n",
            "dense_6 True\n",
            "Layer Configuration:\n",
            "{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 256, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': 1234}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "----------------------------------------\n",
            "dense_7 True\n",
            "Layer Configuration:\n",
            "{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': 1234}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "----------------------------------------\n",
            "dense_8 True\n",
            "Layer Configuration:\n",
            "{'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 16, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': 1234}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "----------------------------------------\n",
            "dense_9 True\n",
            "Layer Configuration:\n",
            "{'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': 1234}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
            "----------------------------------------\n",
            "Model Output Tensors:  KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_9/Softmax:0', description=\"created by layer 'dense_9'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnGSpLfwJbhG",
        "outputId": "c9c13ed2-e093-4af9-9b60-5d490eef890b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for layer in range(len(model.get_weights())):\n",
        "    print('Layer name:', model.weights[layer].name)\n",
        "    print('Layer weights shape:', model.weights[layer].shape)\n",
        "    print('Weight:', model.weights[layer], end = '\\n\\n')\n",
        "    #print(layer.get_config(), end='\\n{}\\n'.format('----'*10))\n",
        "print('Model Output Tensors: ', model.output)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer name: dense_5/kernel:0\n",
            "Layer weights shape: (784, 512)\n",
            "Weight: <tf.Variable 'dense_5/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
            "array([[ 0.03288732,  0.06419916, -0.04038084, ...,  0.0501196 ,\n",
            "        -0.01636986,  0.00267079],\n",
            "       [-0.05238051,  0.01568971,  0.06354105, ..., -0.03587913,\n",
            "        -0.03614935, -0.02498366],\n",
            "       [ 0.0055944 ,  0.01631762,  0.02852674, ...,  0.0222851 ,\n",
            "         0.02921189,  0.01434655],\n",
            "       ...,\n",
            "       [-0.00113957, -0.04627939, -0.04602685, ...,  0.02524721,\n",
            "         0.02275002,  0.03974579],\n",
            "       [-0.01206601,  0.0272265 ,  0.01920352, ...,  0.02996068,\n",
            "         0.00329956, -0.00560015],\n",
            "       [-0.05587083,  0.04224663, -0.04761815, ..., -0.03192603,\n",
            "         0.05160813,  0.03516154]], dtype=float32)>\n",
            "\n",
            "Layer name: dense_5/bias:0\n",
            "Layer weights shape: (512,)\n",
            "Weight: <tf.Variable 'dense_5/bias:0' shape=(512,) dtype=float32, numpy=\n",
            "array([ 1.89845078e-03, -1.82288862e-03,  6.35058945e-03,  1.86150067e-03,\n",
            "        4.48501995e-03,  1.56575232e-03, -1.71804533e-03, -1.33618026e-03,\n",
            "        1.11828768e-03,  9.30214394e-03,  3.05555202e-03,  9.31693416e-04,\n",
            "        5.60593512e-03,  4.08627605e-03,  1.90352870e-03, -6.69741072e-03,\n",
            "       -1.78945193e-03,  8.11786857e-03,  2.85413791e-03, -2.26286333e-03,\n",
            "       -1.42050826e-03,  3.44940257e-04, -4.42306185e-03,  6.59316138e-04,\n",
            "        2.17111409e-03,  1.24243519e-03,  1.08998716e-02,  4.72936966e-03,\n",
            "        1.17593929e-02,  3.01834149e-03,  5.47736709e-04,  1.70564410e-04,\n",
            "       -2.59703898e-04, -1.59924864e-04,  3.30517272e-04,  4.28662729e-03,\n",
            "       -4.54078848e-03, -1.46582676e-03,  1.39733031e-02,  2.93073407e-03,\n",
            "        1.35321142e-02,  9.68815293e-03,  7.61077600e-03,  5.87589387e-03,\n",
            "        2.46448023e-03,  2.87817582e-03, -3.52184102e-03, -2.34480179e-03,\n",
            "        8.94891936e-03,  2.54914514e-03,  9.16042551e-03, -9.33635165e-05,\n",
            "        4.35989257e-03,  1.39246890e-02,  3.47183063e-03, -1.77048217e-03,\n",
            "        1.52433873e-03, -4.20368975e-03,  4.56116768e-03, -2.19400332e-04,\n",
            "        9.64103825e-03,  5.47869364e-03,  2.42920266e-03, -3.46990186e-03,\n",
            "        8.47843476e-03, -4.71955910e-03, -6.34674169e-03,  1.96070271e-03,\n",
            "        3.93878156e-03, -1.60468114e-03,  1.82597747e-03, -1.62360794e-03,\n",
            "        6.40589558e-03, -1.84859766e-03,  2.79747066e-03, -6.77250384e-04,\n",
            "       -3.06131947e-03,  7.24076806e-03,  3.14956554e-03,  4.73400665e-04,\n",
            "        5.27230295e-05, -1.08782295e-03, -6.23521861e-03,  8.50833301e-03,\n",
            "        5.64971520e-03, -1.22972170e-03,  3.86588450e-04,  2.80947471e-03,\n",
            "        1.14906207e-02,  1.45818647e-02,  2.95023946e-03,  6.78914692e-03,\n",
            "        3.75023088e-03,  1.87174454e-02,  1.39731239e-03,  4.30832012e-03,\n",
            "       -3.49805527e-03,  2.33949944e-02,  2.29291545e-04, -1.79784908e-03,\n",
            "        2.18777778e-03, -1.29980396e-03, -3.60070192e-03,  1.05366576e-02,\n",
            "        1.61235061e-04,  3.28593748e-03,  8.53540841e-03, -3.46844597e-03,\n",
            "        6.08367054e-03, -3.79108917e-03,  3.89353093e-03,  1.29951187e-03,\n",
            "        5.60493395e-03,  4.35297005e-03,  2.50611873e-03,  3.40265734e-03,\n",
            "        6.69391453e-03, -5.84979462e-05, -7.79182534e-04,  3.87336756e-03,\n",
            "       -2.44337047e-04,  7.37069920e-03, -4.54570726e-03,  1.68843716e-02,\n",
            "       -5.09942649e-03,  2.22970312e-03, -6.26724621e-04, -6.36614219e-04,\n",
            "        3.44334287e-03,  7.41427112e-03, -3.76958307e-03,  2.23226333e-03,\n",
            "        4.69108764e-03,  9.49237437e-04,  2.34976341e-03, -1.12638611e-03,\n",
            "       -1.71060837e-03,  9.47073975e-04, -3.96090618e-04,  1.05367769e-02,\n",
            "        3.12543038e-04, -2.77978415e-03, -2.25004769e-04, -4.17481177e-04,\n",
            "        2.09905324e-04,  4.56847297e-03,  2.78868154e-03,  3.55724012e-03,\n",
            "        1.96931185e-03,  1.33425964e-03,  3.86644341e-03,  3.12551064e-03,\n",
            "        1.07475407e-02, -4.70509846e-03,  6.56142482e-04, -6.31515961e-03,\n",
            "        4.90361266e-03,  1.28985941e-02,  8.15627351e-03,  1.62783135e-02,\n",
            "        2.51357071e-03, -4.66444576e-03,  6.15623721e-04,  4.85891383e-03,\n",
            "        9.11393960e-04,  7.38058100e-03, -9.57802054e-04,  9.87138879e-03,\n",
            "        2.58988561e-03, -7.45941186e-04,  4.20559489e-04,  5.03031630e-03,\n",
            "        1.64063573e-02,  1.95562700e-03,  3.01297382e-03,  1.31150580e-03,\n",
            "       -1.30694045e-03, -3.75548028e-03, -3.65320640e-03,  3.46151693e-03,\n",
            "        9.31942742e-03,  1.20915622e-02,  5.90686628e-04, -4.40237578e-03,\n",
            "        1.59835815e-02,  2.64063594e-03,  1.07856293e-04,  5.59646403e-04,\n",
            "        1.45280489e-03, -6.59105077e-04, -6.91987108e-03,  1.32784629e-02,\n",
            "        4.23655612e-03,  1.20123755e-02,  2.45359540e-03,  1.33736688e-03,\n",
            "        5.31811407e-03,  8.32948741e-03, -3.83152184e-03, -8.01474729e-04,\n",
            "        1.45899120e-03,  3.21786059e-03,  4.52234410e-03,  1.59201375e-03,\n",
            "        6.99705631e-03,  8.68411735e-03,  1.00568985e-04, -2.82473722e-03,\n",
            "        1.22477859e-02, -1.04836999e-02,  2.17298628e-03, -5.97221497e-03,\n",
            "       -7.56060821e-04, -4.48529888e-03,  1.01213739e-03,  1.29741672e-02,\n",
            "       -3.30016832e-04,  4.52340674e-03, -1.99049478e-03, -9.05016961e-04,\n",
            "       -2.73961505e-05,  4.81096387e-04,  1.46834245e-02, -4.08163201e-03,\n",
            "        9.54978634e-04,  5.76770538e-03, -2.97026383e-03,  7.23325228e-03,\n",
            "       -9.96838789e-03, -1.31189870e-03,  6.73899951e-04, -3.50429816e-03,\n",
            "        5.64920204e-03,  1.18749158e-03, -7.23875419e-05,  1.02217123e-03,\n",
            "        4.32411907e-04, -2.59616086e-03,  1.19485019e-03,  2.35214620e-03,\n",
            "        4.42845374e-03,  5.68889501e-03, -2.90236762e-03,  1.02811456e-02,\n",
            "        5.19744214e-03,  1.17318872e-02,  1.20657613e-04,  9.97224706e-04,\n",
            "        2.95328652e-03, -4.95441863e-03,  2.80403788e-03,  1.36345308e-02,\n",
            "        7.20369583e-03,  6.97233807e-03,  7.99974147e-03,  9.29181406e-04,\n",
            "       -1.29524886e-03,  1.03063462e-02,  1.46083150e-03,  2.14431807e-03,\n",
            "       -2.96214363e-03,  3.05964681e-03,  1.78622119e-02, -2.01299065e-03,\n",
            "        1.65860620e-04, -2.88958033e-03,  2.49549048e-03,  4.50494420e-03,\n",
            "        4.55606874e-04,  4.85955679e-05,  1.57046132e-03,  1.54110405e-03,\n",
            "        4.72460501e-03,  2.81428266e-03,  3.79014923e-03,  9.02154541e-04,\n",
            "        9.98975523e-03,  1.17435325e-02,  2.20558979e-03,  1.39407720e-02,\n",
            "        7.61563797e-03,  1.02694277e-02,  2.71610194e-03,  1.16463769e-02,\n",
            "        1.06023243e-02,  6.23078132e-03,  9.41122044e-03, -3.15864710e-03,\n",
            "        1.37441112e-02,  6.03099074e-03,  5.20107802e-03,  1.09284825e-03,\n",
            "       -4.71895008e-04,  1.44789589e-03,  2.60048695e-02,  5.59450360e-03,\n",
            "       -2.83390051e-03,  3.52791767e-03, -8.92830940e-05,  1.10157067e-03,\n",
            "        2.46798694e-02,  3.64146690e-04, -1.63942750e-03,  2.00129356e-02,\n",
            "        8.46882910e-03, -3.92189343e-03,  1.34947589e-02,  1.71680830e-03,\n",
            "       -1.37517846e-03, -5.05887065e-03,  4.37211012e-04,  1.77127179e-02,\n",
            "        1.23384956e-03, -3.28548858e-03,  2.01612152e-03,  1.44616654e-03,\n",
            "        5.93319023e-03, -2.19422556e-03,  7.73180276e-03,  1.96062797e-03,\n",
            "        6.80815615e-03,  1.70330741e-02,  3.29886912e-03,  1.31253828e-03,\n",
            "       -2.51524919e-03, -4.02511051e-03,  5.00423089e-03,  4.43126680e-03,\n",
            "        2.95293564e-03,  4.08861507e-03,  4.23365273e-03, -1.03384873e-03,\n",
            "       -1.98367750e-03,  8.60584332e-05,  5.13824308e-03,  9.95669607e-03,\n",
            "        9.44507960e-03,  3.85107892e-03, -2.93125235e-03, -8.94314982e-03,\n",
            "        3.66271124e-03,  2.65624421e-03, -1.29036861e-03,  3.16289556e-03,\n",
            "        1.37307793e-02,  9.97813977e-03,  6.50188886e-03, -1.56764232e-04,\n",
            "       -4.57633927e-04,  1.71926431e-02,  1.00536551e-02,  5.40769566e-03,\n",
            "        7.18776649e-03, -2.31542112e-03, -2.97899335e-03,  1.69744908e-05,\n",
            "        8.43163952e-03,  4.27084946e-04, -3.76015599e-03, -8.83349101e-04,\n",
            "       -1.05658208e-03,  3.33020650e-03,  8.77097264e-05, -7.47827487e-03,\n",
            "        1.72636360e-02,  1.54993904e-03,  7.87635241e-03,  3.04260477e-03,\n",
            "        1.00382594e-02,  1.83653552e-03,  4.81855869e-03,  1.72926281e-02,\n",
            "       -4.15501557e-03,  3.28051450e-04,  1.48018484e-03, -2.46427400e-04,\n",
            "        1.69185107e-03, -1.65969323e-04,  5.45899803e-03, -2.02056463e-03,\n",
            "        6.21021353e-03, -1.13668584e-03,  1.02437567e-02,  6.71374612e-03,\n",
            "       -5.19055966e-03,  1.52813888e-03,  6.57306565e-03,  7.62113463e-03,\n",
            "        8.72232486e-05,  1.13993930e-02, -2.95750122e-03, -1.25127251e-03,\n",
            "        9.72926617e-04,  7.39062903e-03,  1.24851316e-02,  7.15589197e-03,\n",
            "       -3.51987057e-03, -9.59784538e-03,  1.60202384e-03,  8.98785982e-03,\n",
            "        9.16815270e-03,  2.91461567e-03,  3.83791397e-03,  1.14333490e-02,\n",
            "       -4.12355457e-03,  2.01420020e-03, -4.68943210e-04,  4.99949744e-03,\n",
            "       -7.91011262e-04,  9.36212833e-04, -2.03096424e-04,  2.21640780e-03,\n",
            "        3.28155956e-03, -5.96908713e-03,  4.15835949e-03,  1.18962163e-02,\n",
            "        7.70952320e-03, -2.06432352e-03,  1.73677574e-03, -5.69044333e-03,\n",
            "       -5.29512297e-04,  1.35684165e-03,  2.40847399e-03,  1.44083537e-02,\n",
            "        1.54734198e-02,  1.24795139e-02,  7.37333903e-03,  1.00120658e-03,\n",
            "        7.49099813e-03,  1.99193228e-03, -1.12821546e-03, -3.29482392e-03,\n",
            "        7.75906956e-03,  2.42742198e-03,  1.80939101e-02, -4.47453605e-03,\n",
            "       -2.78949551e-03,  9.26714763e-03, -8.38461972e-04,  8.94521922e-03,\n",
            "        6.02384238e-03,  6.87470846e-03,  3.28761013e-03,  6.12530624e-03,\n",
            "       -1.86735985e-03,  3.86095815e-03,  5.10715181e-03, -7.88340345e-04,\n",
            "        1.85898039e-02, -4.02831385e-04, -1.76281983e-03,  1.12688774e-02,\n",
            "        3.37594934e-03, -8.02372873e-04,  6.87169202e-04,  8.07287358e-03,\n",
            "       -6.63713133e-03,  8.82594753e-03,  7.25241436e-04,  5.10469731e-03,\n",
            "       -4.48676146e-04,  3.46057070e-03, -3.11630149e-03, -1.53441448e-03,\n",
            "        6.73268980e-04,  8.37022066e-03,  1.83651550e-03,  4.07340936e-04,\n",
            "        5.76170348e-03,  3.07350582e-03,  1.51202851e-03,  4.07143496e-03,\n",
            "        1.44233636e-03,  9.46844276e-03,  4.76200040e-03,  1.08653086e-03,\n",
            "       -4.35937021e-04, -1.97898457e-03,  1.46399473e-03, -3.82499816e-03,\n",
            "        4.95074270e-03, -1.27387582e-03,  4.49483516e-03,  5.86960465e-04,\n",
            "       -8.58684361e-04,  8.02193303e-03,  3.22587974e-03,  9.44832433e-03,\n",
            "       -3.85453203e-03,  1.12588480e-02, -3.25961551e-03,  5.42918104e-04,\n",
            "        1.72116458e-02, -2.29790225e-03,  2.48507527e-03,  2.90407077e-03,\n",
            "        4.67996718e-03,  4.01563337e-03,  1.22159375e-02,  8.69714562e-03,\n",
            "        4.23097191e-03,  4.80822055e-03,  2.46230746e-03, -4.12273919e-03,\n",
            "       -7.57594418e-04, -4.62910021e-03, -1.95407961e-03,  2.52883416e-03,\n",
            "        2.34764926e-02,  1.06007848e-02,  3.40105471e-04,  4.34275251e-03],\n",
            "      dtype=float32)>\n",
            "\n",
            "Layer name: dense_6/kernel:0\n",
            "Layer weights shape: (512, 256)\n",
            "Weight: <tf.Variable 'dense_6/kernel:0' shape=(512, 256) dtype=float32, numpy=\n",
            "array([[ 0.04247188,  0.0837666 , -0.05248749, ...,  0.02871147,\n",
            "         0.05073144,  0.04531113],\n",
            "       [ 0.01533224, -0.01437739,  0.05846503, ...,  0.06546482,\n",
            "        -0.01973605,  0.00328743],\n",
            "       [-0.065572  ,  0.02293373,  0.08680294, ...,  0.00933512,\n",
            "         0.00426296,  0.0515158 ],\n",
            "       ...,\n",
            "       [ 0.05649055,  0.02283636, -0.07324265, ..., -0.032511  ,\n",
            "         0.06440368,  0.0601575 ],\n",
            "       [ 0.05146697,  0.06325673, -0.02756848, ...,  0.05201884,\n",
            "         0.0230339 ,  0.01557716],\n",
            "       [-0.05676564,  0.02305536,  0.04419246, ..., -0.067917  ,\n",
            "         0.01159885, -0.06035128]], dtype=float32)>\n",
            "\n",
            "Layer name: dense_6/bias:0\n",
            "Layer weights shape: (256,)\n",
            "Weight: <tf.Variable 'dense_6/bias:0' shape=(256,) dtype=float32, numpy=\n",
            "array([-1.40684899e-02,  6.26474805e-03,  2.01900513e-03, -2.55439733e-03,\n",
            "       -5.99660736e-04, -1.12375221e-03,  5.25380834e-04,  1.40147181e-02,\n",
            "       -1.38291521e-02,  3.97856534e-03, -1.67092308e-03,  1.38457036e-02,\n",
            "        2.44096533e-04, -1.42675126e-02,  1.57315340e-02,  4.83978912e-03,\n",
            "       -1.04426499e-03,  6.20346866e-04, -9.71376430e-03,  1.96168292e-02,\n",
            "       -1.98441837e-02,  2.90022674e-03,  1.81444827e-02,  8.16564207e-05,\n",
            "       -8.88764916e-05,  2.30923314e-02, -5.52707002e-04, -5.29727759e-03,\n",
            "       -1.09804608e-02,  2.63891071e-02,  2.81452667e-02,  3.82313046e-05,\n",
            "       -4.78566810e-03, -2.02283915e-03,  1.85319427e-02, -8.79074261e-03,\n",
            "        1.45916536e-03, -8.93416535e-03, -6.42880565e-03, -3.33528616e-03,\n",
            "        6.51772227e-03, -1.79418530e-02,  4.28452448e-04,  1.01550296e-03,\n",
            "       -4.77276696e-03,  1.45253632e-03, -3.13081034e-03,  3.30184284e-03,\n",
            "        1.65672768e-02,  4.14512912e-03, -1.18707586e-03, -5.15212814e-05,\n",
            "       -6.09337352e-03, -6.50612696e-04,  2.39362800e-03,  5.48044499e-03,\n",
            "        1.02146370e-02,  1.09131513e-02,  1.21591707e-04, -5.06098382e-03,\n",
            "       -6.69038389e-03,  4.58674069e-04, -7.71352835e-03,  5.62621886e-03,\n",
            "        1.19264303e-02,  7.96304084e-03, -4.11844952e-03, -3.73753224e-04,\n",
            "       -2.40923278e-03, -1.84748729e-03,  8.81677668e-04, -2.70729186e-03,\n",
            "        2.78190281e-02,  1.41022466e-02, -1.36528746e-03,  1.30878505e-03,\n",
            "        7.75360083e-03,  9.74979345e-03, -1.58093579e-03,  1.00350378e-04,\n",
            "        3.03329509e-02,  2.03444567e-02,  1.29317287e-02,  6.51867827e-03,\n",
            "       -5.02345571e-03, -1.48111936e-02,  1.53337447e-02, -3.39343795e-03,\n",
            "        2.46676710e-02,  1.80280209e-02,  1.76141430e-02,  7.23102503e-03,\n",
            "        5.49461460e-03, -1.63819781e-03,  7.68355851e-04,  1.86433410e-03,\n",
            "       -5.54840174e-03,  2.64414703e-03, -3.55533953e-03,  2.43767281e-05,\n",
            "       -4.04534582e-03, -6.28543145e-04,  1.84545573e-02,  1.30961919e-02,\n",
            "        2.11794092e-03, -5.35273692e-03, -1.26267402e-02,  2.59379740e-04,\n",
            "        1.26416106e-02, -3.30910715e-03,  2.29239240e-02,  2.54817982e-03,\n",
            "        1.08026555e-02,  4.15220996e-03, -3.57599719e-03, -4.11845557e-03,\n",
            "       -8.66207585e-04,  1.05926255e-03,  1.58958770e-02,  7.06141023e-03,\n",
            "        3.00506456e-03,  8.64127465e-03, -6.24650856e-03, -2.47449661e-03,\n",
            "       -3.68641294e-03,  1.68121997e-02, -1.01680625e-02,  1.32227084e-02,\n",
            "        1.67351793e-02,  3.74859525e-03,  3.37033020e-03, -4.92441189e-03,\n",
            "       -2.59835069e-04,  1.80958956e-02,  1.69784371e-02, -1.42803369e-03,\n",
            "        6.44881558e-03,  5.30279614e-03,  3.73121165e-03,  1.04418192e-02,\n",
            "        2.34303574e-04,  3.25292051e-02,  4.18298459e-03,  9.45766224e-05,\n",
            "       -3.65132256e-03,  1.14696065e-03,  1.86839383e-02, -1.65182122e-04,\n",
            "       -5.77992701e-04,  1.46573712e-03, -5.32911252e-03,  8.82944185e-03,\n",
            "        2.38132640e-03, -1.74458046e-02,  1.32616963e-02,  4.10932320e-04,\n",
            "        4.26904438e-03,  8.95628333e-03,  1.54481092e-02,  3.49707156e-03,\n",
            "        7.27561885e-04,  6.48687501e-03, -1.08726267e-02,  2.52304487e-02,\n",
            "       -6.43696683e-03,  9.47519299e-03, -7.26316066e-04,  6.93286769e-03,\n",
            "        6.32353313e-03, -8.39675311e-04,  3.43365991e-03,  3.03622559e-02,\n",
            "        2.08414812e-03, -1.53139664e-03, -1.66839026e-02,  6.73640985e-03,\n",
            "       -4.65539237e-03, -1.20455422e-03, -1.13747909e-03,  6.75035687e-03,\n",
            "        6.27091480e-03,  6.12282706e-03, -1.23291975e-03,  1.16989454e-02,\n",
            "       -7.07875751e-03,  4.84380545e-03, -2.44219205e-04,  1.44642089e-02,\n",
            "       -6.81906147e-03,  2.32961916e-04, -9.78656695e-04,  2.35691108e-02,\n",
            "       -8.00748542e-03,  9.94193275e-03,  4.47800662e-03, -6.61206432e-03,\n",
            "        2.52315914e-03, -7.56103406e-03,  2.11738935e-03,  6.46194257e-03,\n",
            "       -5.06345415e-04,  1.47673115e-03, -1.66710820e-02,  6.44493382e-04,\n",
            "        1.07090045e-02,  1.09110689e-02,  5.74141415e-03,  1.54419895e-02,\n",
            "        1.63494213e-03,  1.09925810e-02,  1.12240752e-02, -3.90158151e-03,\n",
            "       -1.71604930e-04, -1.52890594e-03,  3.33656440e-04,  1.79807264e-02,\n",
            "        8.92119278e-05,  7.83619657e-03, -1.73639599e-03, -1.11492388e-02,\n",
            "        9.58878372e-04, -1.56607910e-03,  1.90925058e-02,  1.00963647e-02,\n",
            "        4.69502946e-03,  4.24033822e-03,  2.38878676e-03,  2.90385867e-03,\n",
            "       -1.05726440e-03, -2.72911275e-03,  5.71878161e-03,  1.20741166e-02,\n",
            "       -1.56741211e-04, -1.56028557e-03,  2.22018524e-03, -2.27882934e-04,\n",
            "       -1.00601884e-03, -4.34190501e-03,  1.73464566e-02, -5.96649293e-03,\n",
            "        9.38600395e-03,  3.13330651e-03, -4.05610679e-03, -4.69128788e-03,\n",
            "        3.19913495e-04, -1.37181289e-03, -1.56285032e-03, -1.09547233e-04,\n",
            "        8.17358377e-04,  7.76160043e-03,  8.58213054e-04,  5.38067939e-03,\n",
            "        1.76962819e-02,  1.76765341e-02,  3.53895463e-02, -2.09990842e-03],\n",
            "      dtype=float32)>\n",
            "\n",
            "Layer name: dense_7/kernel:0\n",
            "Layer weights shape: (256, 32)\n",
            "Weight: <tf.Variable 'dense_7/kernel:0' shape=(256, 32) dtype=float32, numpy=\n",
            "array([[ 0.06950933,  0.14135343, -0.08565506, ..., -0.01213251,\n",
            "         0.11351655,  0.13922292],\n",
            "       [-0.02270501,  0.14199378,  0.01147289, ..., -0.05902383,\n",
            "        -0.03630409, -0.07759586],\n",
            "       [-0.08428127, -0.04993449, -0.09422833, ..., -0.05205476,\n",
            "        -0.02726998,  0.12711471],\n",
            "       ...,\n",
            "       [-0.12367559, -0.05120027,  0.13348334, ...,  0.08231384,\n",
            "        -0.05927079, -0.0626272 ],\n",
            "       [ 0.07469418,  0.08149133, -0.06073131, ..., -0.01192378,\n",
            "        -0.01528107, -0.09747233],\n",
            "       [ 0.01416621, -0.13494012, -0.04991911, ...,  0.0979381 ,\n",
            "        -0.14415549,  0.14259012]], dtype=float32)>\n",
            "\n",
            "Layer name: dense_7/bias:0\n",
            "Layer weights shape: (32,)\n",
            "Weight: <tf.Variable 'dense_7/bias:0' shape=(32,) dtype=float32, numpy=\n",
            "array([-8.22683796e-03,  4.78217815e-04,  2.95065285e-04,  2.42151972e-02,\n",
            "        1.72013100e-02,  8.35106000e-02,  2.63098832e-02,  1.25120981e-02,\n",
            "       -7.77832838e-03,  2.35293899e-02,  1.99968256e-02,  2.11390885e-04,\n",
            "        5.55792227e-02,  7.48275453e-03,  6.46999180e-02, -1.54877035e-02,\n",
            "       -8.65842775e-03, -9.58529301e-03,  1.00364399e-04, -1.64015929e-03,\n",
            "       -2.42928062e-02,  8.96359701e-03,  5.85961454e-02,  4.40681819e-04,\n",
            "       -1.34135066e-02,  2.44039819e-02,  2.65153050e-02, -8.77746152e-06,\n",
            "        3.20551731e-02, -2.09005307e-02,  1.12745678e-03, -4.40771393e-02],\n",
            "      dtype=float32)>\n",
            "\n",
            "Layer name: dense_8/kernel:0\n",
            "Layer weights shape: (32, 16)\n",
            "Weight: <tf.Variable 'dense_8/kernel:0' shape=(32, 16) dtype=float32, numpy=\n",
            "array([[ 0.1706729 ,  0.33828676, -0.20983306,  0.23975566, -0.06396012,\n",
            "        -0.20890412, -0.02448472,  0.3441409 ,  0.3484738 , -0.19815932,\n",
            "        -0.00264065,  0.04241682, -0.15306771,  0.2024269 , -0.04934072,\n",
            "        -0.16474842],\n",
            "       [ 0.06426553, -0.0126465 ,  0.2324538 ,  0.27428192,  0.3257561 ,\n",
            "         0.17767704,  0.13689297, -0.1410314 ,  0.365872  ,  0.15406068,\n",
            "         0.10372119, -0.23704363,  0.15834816, -0.04150777,  0.3356373 ,\n",
            "         0.35801247],\n",
            "       [-0.07131343,  0.333157  ,  0.02639148, -0.11239824, -0.24934019,\n",
            "         0.17560098, -0.10328937, -0.00971585, -0.3098538 , -0.06544858,\n",
            "         0.34824485,  0.03067277,  0.02385875, -0.30478725, -0.00398794,\n",
            "         0.30033097],\n",
            "       [-0.02359578,  0.05172206,  0.23215225, -0.1555849 ,  0.28500074,\n",
            "         0.13502659, -0.14591414,  0.25622004,  0.33006325,  0.17698322,\n",
            "         0.21530356, -0.16594249, -0.01528787, -0.15479134, -0.10663927,\n",
            "        -0.20734367],\n",
            "       [-0.25728482, -0.17803487, -0.23030904,  0.492072  , -0.32204747,\n",
            "        -0.3180629 , -0.23769872, -0.28328127,  0.35153633,  0.09972519,\n",
            "         0.13541356, -0.050711  , -0.19267412,  0.28936893, -0.12391937,\n",
            "         0.10673754],\n",
            "       [-0.21062486,  0.34508023,  0.10146937, -0.27247548, -0.25843737,\n",
            "         0.34927362,  0.3406008 ,  0.04373467, -0.1894126 ,  0.39285597,\n",
            "         0.24380502,  0.12528798, -0.11744001, -0.13072982, -0.09281229,\n",
            "         0.26180503],\n",
            "       [-0.10754755,  0.14036512, -0.3450091 ,  0.27667058, -0.29070044,\n",
            "         0.16460352,  0.10768282,  0.17157224, -0.11704019, -0.16731465,\n",
            "        -0.12915534, -0.07573399, -0.07899487, -0.07969456,  0.09955113,\n",
            "         0.22505182],\n",
            "       [ 0.03672838, -0.23049386, -0.2459267 , -0.03716044,  0.32043934,\n",
            "         0.5145836 , -0.2200676 , -0.12065752, -0.46087965, -0.34669974,\n",
            "         0.22933963,  0.12091985,  0.22945757,  0.01891345, -0.04530163,\n",
            "        -0.1901181 ],\n",
            "       [-0.11091119,  0.04060087, -0.3077165 , -0.02030065,  0.10001819,\n",
            "        -0.33256462,  0.3669647 ,  0.04687294,  0.39682484,  0.21260966,\n",
            "        -0.04145687,  0.23048164, -0.34277612,  0.26408452,  0.3082957 ,\n",
            "         0.23024347],\n",
            "       [-0.21653809, -0.25019965, -0.01042776,  0.41918558, -0.11423571,\n",
            "         0.06010663, -0.2602473 ,  0.00369054,  0.02990886,  0.22918537,\n",
            "         0.19470541, -0.09582514,  0.17001338,  0.06892508,  0.1257931 ,\n",
            "         0.2675221 ],\n",
            "       [ 0.00630549,  0.2268969 , -0.24529968,  0.29316851, -0.1951036 ,\n",
            "        -0.20812283, -0.17101748,  0.06339848,  0.14488514,  0.05240222,\n",
            "        -0.18642804,  0.37295574, -0.04833363, -0.17781371, -0.05417613,\n",
            "        -0.05197113],\n",
            "       [-0.27772555, -0.18079318, -0.25631225,  0.2103666 , -0.06005624,\n",
            "        -0.20543934,  0.34676173, -0.3228378 ,  0.02067299,  0.27880204,\n",
            "        -0.25553536,  0.17829503,  0.0813279 ,  0.0738755 , -0.2672332 ,\n",
            "         0.32604724],\n",
            "       [-0.14259297,  0.00815306, -0.18431868, -0.29127878, -0.04280973,\n",
            "         0.09578104,  0.00175928,  0.28826603,  0.26260293, -0.00633161,\n",
            "        -0.3424824 ,  0.30818623, -0.04339066,  0.1849767 , -0.21799152,\n",
            "        -0.34836805],\n",
            "       [-0.02522229,  0.23385209, -0.3529973 ,  0.06198729,  0.0719237 ,\n",
            "         0.16621135,  0.19261731,  0.00161376,  0.17892054, -0.08618833,\n",
            "         0.22271314, -0.27912027, -0.11819843,  0.24514171,  0.2537309 ,\n",
            "        -0.34248325],\n",
            "       [-0.23023283, -0.07852779, -0.0394906 , -0.10043706, -0.15039355,\n",
            "         0.06589192,  0.20299672, -0.0502541 , -0.01914947,  0.08201636,\n",
            "         0.00276208, -0.22225586,  0.30283773, -0.33811757, -0.06176803,\n",
            "        -0.2650717 ],\n",
            "       [-0.05033333, -0.34366515, -0.14333658,  0.31684312,  0.05985034,\n",
            "        -0.12525953, -0.00374252, -0.02567829,  0.12363455,  0.02043066,\n",
            "         0.4043694 ,  0.04792703,  0.29709905,  0.14612387,  0.27702102,\n",
            "         0.1952328 ],\n",
            "       [ 0.05639203, -0.02549139,  0.23502986, -0.29941985, -0.32358816,\n",
            "        -0.3256203 , -0.2883104 , -0.13031435,  0.19829908, -0.12934537,\n",
            "        -0.37248674,  0.24229419,  0.03462254,  0.33887756, -0.18565513,\n",
            "        -0.07641444],\n",
            "       [ 0.36292836,  0.222016  ,  0.02682699, -0.24714808, -0.00331069,\n",
            "         0.4672857 , -0.37097904,  0.05068756, -0.18368615, -0.370163  ,\n",
            "        -0.04464034, -0.2620588 ,  0.26768404,  0.00968304, -0.05331575,\n",
            "        -0.26560602],\n",
            "       [ 0.21336134, -0.12950623, -0.2629859 , -0.19648911, -0.29728264,\n",
            "        -0.08918075,  0.28814128,  0.29347277,  0.06839041,  0.16487175,\n",
            "        -0.07946479,  0.08103605,  0.3389279 ,  0.11120123, -0.26776698,\n",
            "         0.08563749],\n",
            "       [ 0.18238474, -0.1257852 , -0.24129064, -0.11499324,  0.0890737 ,\n",
            "         0.199679  ,  0.09687997, -0.2942916 , -0.37368774,  0.10236382,\n",
            "         0.07516551, -0.01394448,  0.12673144,  0.20532176,  0.3356853 ,\n",
            "        -0.01092913],\n",
            "       [ 0.04906408,  0.29958004, -0.12593262, -0.18594676,  0.17663069,\n",
            "        -0.03554678, -0.31702605, -0.040853  , -0.20972435,  0.18513153,\n",
            "        -0.11046913,  0.12603052, -0.27538928, -0.31986225,  0.2895702 ,\n",
            "         0.3328899 ],\n",
            "       [ 0.36428556,  0.29667714,  0.15178894, -0.1324774 , -0.02057964,\n",
            "         0.23607117, -0.14141886, -0.08740914,  0.10780153,  0.03763582,\n",
            "         0.3498896 ,  0.12635586, -0.00562291, -0.14143842, -0.25887594,\n",
            "        -0.22940692],\n",
            "       [ 0.07454623,  0.40336344, -0.22077376, -0.28943706,  0.14667466,\n",
            "         0.19592127,  0.344741  , -0.13694733,  0.26645213,  0.46711275,\n",
            "        -0.11369726, -0.04878566,  0.303042  , -0.00631164, -0.02418961,\n",
            "         0.1730677 ],\n",
            "       [-0.23381457, -0.09785475,  0.08753204, -0.23687685, -0.10564181,\n",
            "        -0.17252673, -0.05812097, -0.29991707,  0.10844675, -0.11014652,\n",
            "        -0.1336825 , -0.14673722, -0.10056514,  0.24367422, -0.17585397,\n",
            "        -0.3012077 ],\n",
            "       [ 0.13190445,  0.13417555, -0.1519642 ,  0.1305299 , -0.13123748,\n",
            "        -0.3230267 ,  0.30974147,  0.168553  , -0.29714444, -0.09049965,\n",
            "         0.10982559,  0.12568782,  0.00732069, -0.08871488,  0.02544476,\n",
            "        -0.33092895],\n",
            "       [ 0.08889966,  0.2128304 ,  0.13865352,  0.30620623,  0.20544228,\n",
            "         0.11176853,  0.2758758 ,  0.288038  ,  0.16902815, -0.1572998 ,\n",
            "        -0.3447078 ,  0.43033776, -0.12813306, -0.14252336, -0.11698224,\n",
            "        -0.33322552],\n",
            "       [ 0.26380914, -0.10375104,  0.09404723,  0.19095153, -0.196595  ,\n",
            "         0.1744471 , -0.18220891, -0.3331448 ,  0.2898666 , -0.06268962,\n",
            "        -0.21719307, -0.06022377, -0.11558542, -0.00997595, -0.1208614 ,\n",
            "         0.19564028],\n",
            "       [ 0.3037364 ,  0.21474089, -0.29799768, -0.27146083,  0.02857951,\n",
            "         0.03242948, -0.23409669, -0.1315413 ,  0.33408797, -0.2985632 ,\n",
            "        -0.09035763,  0.22598234,  0.3524565 ,  0.06949005, -0.24658234,\n",
            "         0.21342942],\n",
            "       [ 0.0700938 ,  0.23467545, -0.3093661 ,  0.21308278,  0.29106295,\n",
            "         0.14914598, -0.15348563, -0.3021132 ,  0.42271432,  0.3991063 ,\n",
            "         0.33065474, -0.27262965,  0.00339383,  0.26022378,  0.27253297,\n",
            "        -0.29598215],\n",
            "       [-0.23529838,  0.19534191, -0.0855682 ,  0.33013496,  0.22426042,\n",
            "         0.14454745, -0.0315246 ,  0.19855958, -0.35020128, -0.2468693 ,\n",
            "         0.25257394, -0.03920794,  0.33908507,  0.27532914, -0.3158627 ,\n",
            "         0.04446708],\n",
            "       [-0.26821738, -0.17350428, -0.2901344 , -0.0528076 , -0.32113367,\n",
            "         0.33811104,  0.2339495 ,  0.12463262,  0.33286074, -0.09493387,\n",
            "        -0.24132425,  0.2894477 ,  0.11405206, -0.1443653 ,  0.24171753,\n",
            "        -0.2272767 ],\n",
            "       [ 0.21126144,  0.1781553 ,  0.15867049,  0.10203645,  0.17248902,\n",
            "        -0.29695842,  0.2715933 , -0.35253575,  0.17868368, -0.1536602 ,\n",
            "         0.14689867,  0.3054084 , -0.13238122,  0.28932583, -0.08586654,\n",
            "         0.02730576]], dtype=float32)>\n",
            "\n",
            "Layer name: dense_8/bias:0\n",
            "Layer weights shape: (16,)\n",
            "Weight: <tf.Variable 'dense_8/bias:0' shape=(16,) dtype=float32, numpy=\n",
            "array([-0.03089224, -0.02662988, -0.00067343,  0.06411781, -0.09680779,\n",
            "        0.15177134,  0.04695107, -0.00796767,  0.01791414,  0.12600198,\n",
            "       -0.0267856 ,  0.00085299, -0.02127542, -0.05445017, -0.04319612,\n",
            "       -0.06959829], dtype=float32)>\n",
            "\n",
            "Layer name: dense_9/kernel:0\n",
            "Layer weights shape: (16, 10)\n",
            "Weight: <tf.Variable 'dense_9/kernel:0' shape=(16, 10) dtype=float32, numpy=\n",
            "array([[ 0.22644715,  0.4360309 , -0.31023598,  0.25219655, -0.07778797,\n",
            "        -0.26369232, -0.11970209,  0.47489095,  0.6070959 , -0.2774756 ],\n",
            "       [ 0.08581234, -0.07751153, -0.33897746,  0.25057918, -0.07961907,\n",
            "        -0.0503605 , -0.05317616, -0.07291057,  0.5704557 ,  0.24997474],\n",
            "       [ 0.41257808,  0.2806303 ,  0.17167006, -0.18804203,  0.41859767,\n",
            "         0.12180093,  0.09936057, -0.28631338,  0.20036355, -0.02827514],\n",
            "       [ 0.5733171 ,  0.6534514 , -0.2050664 ,  0.53441817,  0.12835762,\n",
            "        -0.26554096, -0.15777504,  0.02796568, -0.34554723, -0.13841386],\n",
            "       [-0.42952847, -0.13228513,  0.5195384 , -0.00385608,  0.07427268,\n",
            "        -0.42350313, -0.05943665,  0.43465576,  0.03875498,  0.06195294],\n",
            "       [ 0.513891  , -0.3510486 ,  0.41951445,  0.02581296, -0.09253064,\n",
            "         0.42043963,  0.4844266 ,  0.00121624,  0.4718281 , -0.3348087 ],\n",
            "       [-0.0698509 , -0.26179698, -0.17334495, -0.27157673, -0.30404758,\n",
            "        -0.08424533, -0.40132403,  0.62169325, -0.37126237, -0.45875022],\n",
            "       [-0.2669952 , -0.3761386 ,  0.41870457,  0.08099825,  0.15013911,\n",
            "        -0.0863174 , -0.2672002 ,  0.35411862, -0.18710065,  0.14420813],\n",
            "       [-0.43756053,  0.41128236,  0.02038528, -0.5273715 , -0.3062805 ,\n",
            "         0.48922879,  0.1474436 ,  0.12907884, -0.20075405,  0.69831425],\n",
            "       [ 0.3303403 ,  0.05015041, -0.21338642, -0.13392693, -0.12248334,\n",
            "         0.5860374 , -0.34225222,  0.23120101, -0.4366914 ,  0.2306703 ],\n",
            "       [-0.35351327,  0.09744284,  0.19845764,  0.3120494 ,  0.06186976,\n",
            "        -0.25023556, -0.13098606, -0.32811448, -0.07663642, -0.15884627],\n",
            "       [ 0.16255672,  0.24124913, -0.01351909, -0.30363676, -0.34745497,\n",
            "        -0.17380215,  0.5386207 ,  0.47087288, -0.2813539 , -0.16264097],\n",
            "       [-0.4251992 , -0.41963696,  0.32665858, -0.00469587,  0.45495012,\n",
            "        -0.03581075, -0.03513936, -0.388181  , -0.13878585, -0.08058869],\n",
            "       [-0.4276723 , -0.01559107,  0.00234976, -0.48950198,  0.62259734,\n",
            "         0.05027068,  0.41940424,  0.05227763,  0.01090532,  0.40305832],\n",
            "       [-0.4800227 ,  0.3381729 ,  0.4088309 ,  0.31910157, -0.2976396 ,\n",
            "        -0.31468496, -0.0802426 ,  0.5141269 , -0.18333541,  0.09722306],\n",
            "       [-0.35840455, -0.03526301,  0.03030177,  0.408552  ,  0.20857745,\n",
            "        -0.21280134,  0.16271421,  0.10144115,  0.11573367,  0.44713134]],\n",
            "      dtype=float32)>\n",
            "\n",
            "Layer name: dense_9/bias:0\n",
            "Layer weights shape: (10,)\n",
            "Weight: <tf.Variable 'dense_9/bias:0' shape=(10,) dtype=float32, numpy=\n",
            "array([ 1.20804608e-01, -6.75649196e-02, -8.48548338e-02, -2.22057998e-02,\n",
            "        1.78982504e-02,  2.10362807e-01, -8.75234946e-06, -1.00788318e-01,\n",
            "        3.81718315e-02, -1.11815475e-01], dtype=float32)>\n",
            "\n",
            "Model Output Tensors:  KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='dense_9/Softmax:0', description=\"created by layer 'dense_9'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjhy5S84Hoo6"
      },
      "source": [
        "# Regularization\n",
        "\n",
        "Regularization is a technique that makes slight changes to the learning algorithm to reduce overfitting and generalize better. This in turn improves the performance of the model even on invisible data (test set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRcmNqDpOdNr"
      },
      "source": [
        "### L1 Kernel/Bias regularization\n",
        "\n",
        "Applying [L1 regularization](https://keras.io/api/layers/regularizers/) to the kernel and bias values. New loss function: $$L(x,y) = L(x,y) + \\lambda\\sum_{j=0}^{M}|W_j|$$\n",
        "\n",
        "where:\n",
        "*   $\\lambda$ parameter controls the impact of regularization\n",
        "*   $W$ corresponds to the model weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eQZGdWHOb89",
        "outputId": "5cb5dce0-3669-4279-cb1b-dcb08a08f5ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model_l1 = Sequential()\n",
        "model_l1.add(Dense(512, input_shape=(dims,), activation = \"relu\",kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
        "model_l1.add(Dense(256, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
        "model_l1.add(Dense(32, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
        "model_l1.add(Dense(16, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l1(0.01), bias_regularizer=regularizers.l1(0.01)))\n",
        "model_l1.add(Dense(nb_classes, activation = \"softmax\", kernel_initializer=initializer))\n",
        "\n",
        "model_l1.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model_l1.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
        "              metrics=['accuracy'])\n",
        "model_l1.fit(X_train, Y_train, batch_size=128, \n",
        "                            epochs=20, verbose=2, validation_data=(X_val, Y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "352/352 - 2s - loss: 194.3665 - accuracy: 0.2849 - val_loss: 185.0439 - val_accuracy: 0.3831\n",
            "Epoch 2/20\n",
            "352/352 - 2s - loss: 176.1348 - accuracy: 0.4115 - val_loss: 167.3177 - val_accuracy: 0.4243\n",
            "Epoch 3/20\n",
            "352/352 - 2s - loss: 158.8855 - accuracy: 0.4389 - val_loss: 150.5419 - val_accuracy: 0.4449\n",
            "Epoch 4/20\n",
            "352/352 - 2s - loss: 142.5757 - accuracy: 0.4552 - val_loss: 134.7050 - val_accuracy: 0.4532\n",
            "Epoch 5/20\n",
            "352/352 - 2s - loss: 127.2074 - accuracy: 0.4599 - val_loss: 119.8069 - val_accuracy: 0.4594\n",
            "Epoch 6/20\n",
            "352/352 - 1s - loss: 112.7731 - accuracy: 0.4640 - val_loss: 105.8406 - val_accuracy: 0.4644\n",
            "Epoch 7/20\n",
            "352/352 - 2s - loss: 99.2715 - accuracy: 0.4669 - val_loss: 92.8076 - val_accuracy: 0.4671\n",
            "Epoch 8/20\n",
            "352/352 - 2s - loss: 86.7020 - accuracy: 0.4697 - val_loss: 80.7074 - val_accuracy: 0.4669\n",
            "Epoch 9/20\n",
            "352/352 - 1s - loss: 75.0699 - accuracy: 0.4703 - val_loss: 69.5460 - val_accuracy: 0.4673\n",
            "Epoch 10/20\n",
            "352/352 - 2s - loss: 64.3757 - accuracy: 0.4695 - val_loss: 59.3245 - val_accuracy: 0.4626\n",
            "Epoch 11/20\n",
            "352/352 - 1s - loss: 54.6229 - accuracy: 0.4666 - val_loss: 50.0417 - val_accuracy: 0.4596\n",
            "Epoch 12/20\n",
            "352/352 - 2s - loss: 45.8047 - accuracy: 0.4624 - val_loss: 41.6930 - val_accuracy: 0.4546\n",
            "Epoch 13/20\n",
            "352/352 - 2s - loss: 37.9220 - accuracy: 0.4581 - val_loss: 34.2787 - val_accuracy: 0.4479\n",
            "Epoch 14/20\n",
            "352/352 - 2s - loss: 30.9735 - accuracy: 0.4516 - val_loss: 27.8010 - val_accuracy: 0.4414\n",
            "Epoch 15/20\n",
            "352/352 - 2s - loss: 24.9659 - accuracy: 0.4460 - val_loss: 22.2657 - val_accuracy: 0.4399\n",
            "Epoch 16/20\n",
            "352/352 - 2s - loss: 19.8976 - accuracy: 0.4436 - val_loss: 17.6663 - val_accuracy: 0.4380\n",
            "Epoch 17/20\n",
            "352/352 - 2s - loss: 15.7587 - accuracy: 0.4445 - val_loss: 13.9868 - val_accuracy: 0.4429\n",
            "Epoch 18/20\n",
            "352/352 - 1s - loss: 12.5217 - accuracy: 0.4570 - val_loss: 11.1862 - val_accuracy: 0.4657\n",
            "Epoch 19/20\n",
            "352/352 - 2s - loss: 10.1264 - accuracy: 0.4814 - val_loss: 9.1815 - val_accuracy: 0.4765\n",
            "Epoch 20/20\n",
            "352/352 - 2s - loss: 8.4523 - accuracy: 0.4813 - val_loss: 7.7831 - val_accuracy: 0.4634\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3869399890>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwQdMmBMT9b9"
      },
      "source": [
        "### L2 Kernel/Bias regularization\n",
        "\n",
        "Applying [L2 regularization](https://keras.io/api/layers/regularizers/) to the kernel and bias values. New loss function: $$L(x,y) = L(x,y) + \\lambda\\sum_{j=0}^{M}W_j^2$$\n",
        "\n",
        "where:\n",
        "*   $\\lambda$ parameter controls the impact of regularization\n",
        "*   $W$ corresponds to the model weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIpKz5f3T9cB",
        "outputId": "84c009b1-fcf7-4f90-a3a7-6a7168a9700a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_l2 = Sequential()\n",
        "model_l2.add(Dense(512, input_shape=(dims,), activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01)))\n",
        "model_l2.add(Dense(256, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01)))\n",
        "model_l2.add(Dense(32, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01)))\n",
        "model_l2.add(Dense(16, activation = \"relu\", kernel_initializer=initializer, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01)))\n",
        "model_l2.add(Dense(nb_classes, activation = \"softmax\"))\n",
        "\n",
        "model_l2.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model_l2.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
        "              metrics=['accuracy'])\n",
        "model_l2.fit(X_train, Y_train, batch_size=128, \n",
        "                            epochs=20, verbose=2, validation_data=(X_val, Y_val))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "352/352 - 3s - loss: 12.4422 - accuracy: 0.2996 - val_loss: 12.2227 - val_accuracy: 0.4080\n",
            "Epoch 2/20\n",
            "352/352 - 2s - loss: 12.0224 - accuracy: 0.4546 - val_loss: 11.8262 - val_accuracy: 0.4792\n",
            "Epoch 3/20\n",
            "352/352 - 2s - loss: 11.6351 - accuracy: 0.5148 - val_loss: 11.4478 - val_accuracy: 0.5715\n",
            "Epoch 4/20\n",
            "352/352 - 2s - loss: 11.2681 - accuracy: 0.6250 - val_loss: 11.1007 - val_accuracy: 0.6483\n",
            "Epoch 5/20\n",
            "352/352 - 2s - loss: 10.9534 - accuracy: 0.6595 - val_loss: 10.8208 - val_accuracy: 0.6629\n",
            "Epoch 6/20\n",
            "352/352 - 2s - loss: 10.7018 - accuracy: 0.6700 - val_loss: 10.5936 - val_accuracy: 0.6711\n",
            "Epoch 7/20\n",
            "352/352 - 2s - loss: 10.4926 - accuracy: 0.6822 - val_loss: 10.3994 - val_accuracy: 0.6867\n",
            "Epoch 8/20\n",
            "352/352 - 2s - loss: 10.3096 - accuracy: 0.6968 - val_loss: 10.2261 - val_accuracy: 0.6996\n",
            "Epoch 9/20\n",
            "352/352 - 2s - loss: 10.1430 - accuracy: 0.7096 - val_loss: 10.0663 - val_accuracy: 0.7111\n",
            "Epoch 10/20\n",
            "352/352 - 2s - loss: 9.9882 - accuracy: 0.7203 - val_loss: 9.9153 - val_accuracy: 0.7247\n",
            "Epoch 11/20\n",
            "352/352 - 2s - loss: 9.8412 - accuracy: 0.7301 - val_loss: 9.7715 - val_accuracy: 0.7355\n",
            "Epoch 12/20\n",
            "352/352 - 2s - loss: 9.7001 - accuracy: 0.7405 - val_loss: 9.6356 - val_accuracy: 0.7411\n",
            "Epoch 13/20\n",
            "352/352 - 2s - loss: 9.5639 - accuracy: 0.7482 - val_loss: 9.4995 - val_accuracy: 0.7487\n",
            "Epoch 14/20\n",
            "352/352 - 2s - loss: 9.4315 - accuracy: 0.7552 - val_loss: 9.3707 - val_accuracy: 0.7551\n",
            "Epoch 15/20\n",
            "352/352 - 2s - loss: 9.3025 - accuracy: 0.7610 - val_loss: 9.2425 - val_accuracy: 0.7585\n",
            "Epoch 16/20\n",
            "352/352 - 2s - loss: 9.1765 - accuracy: 0.7666 - val_loss: 9.1183 - val_accuracy: 0.7648\n",
            "Epoch 17/20\n",
            "352/352 - 1s - loss: 9.0529 - accuracy: 0.7718 - val_loss: 8.9961 - val_accuracy: 0.7704\n",
            "Epoch 18/20\n",
            "352/352 - 2s - loss: 8.9319 - accuracy: 0.7768 - val_loss: 8.8765 - val_accuracy: 0.7717\n",
            "Epoch 19/20\n",
            "352/352 - 2s - loss: 8.8131 - accuracy: 0.7809 - val_loss: 8.7579 - val_accuracy: 0.7768\n",
            "Epoch 20/20\n",
            "352/352 - 2s - loss: 8.6963 - accuracy: 0.7838 - val_loss: 8.6437 - val_accuracy: 0.7809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38691910d0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNLRfzCJgSkW"
      },
      "source": [
        "### Weight Control\n",
        "\n",
        "We will analyze how the weights have changed by introducing the penalties in the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q7KxyEQg62E",
        "outputId": "3d5d7028-827d-4221-9fde-c59c2c17de15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Layers name:', model.weights[6].name)\n",
        "print('Layers kernel shape:', model.weights[6].shape)\n",
        "print('Kernel:', model.weights[6][0], end = '\\n\\n')\n",
        "print('Layers name:', model.weights[7].name)\n",
        "print('Layers kernel shape:', model.weights[7].shape)\n",
        "print('Kernel:', model.weights[7])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers name: dense_8/kernel:0\n",
            "Layers kernel shape: (32, 16)\n",
            "Kernel: tf.Tensor(\n",
            "[ 0.1706729   0.33828676 -0.20983306  0.23975566 -0.06396012 -0.20890412\n",
            " -0.02448472  0.3441409   0.3484738  -0.19815932 -0.00264065  0.04241682\n",
            " -0.15306771  0.2024269  -0.04934072 -0.16474842], shape=(16,), dtype=float32)\n",
            "\n",
            "Layers name: dense_8/bias:0\n",
            "Layers kernel shape: (16,)\n",
            "Kernel: <tf.Variable 'dense_8/bias:0' shape=(16,) dtype=float32, numpy=\n",
            "array([-0.03089224, -0.02662988, -0.00067343,  0.06411781, -0.09680779,\n",
            "        0.15177134,  0.04695107, -0.00796767,  0.01791414,  0.12600198,\n",
            "       -0.0267856 ,  0.00085299, -0.02127542, -0.05445017, -0.04319612,\n",
            "       -0.06959829], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDLSB3TZT9cV",
        "outputId": "8decb3c9-0210-4995-a3df-67dfe925732d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Layers name:', model_l2.weights[6].name)\n",
        "print('Layers kernel shape:', model_l2.weights[6].shape)\n",
        "print('Kernel:', model_l2.weights[6][0], end = '\\n\\n')\n",
        "print('Layers name:', model_l2.weights[7].name)\n",
        "print('Layers kernel shape:', model_l2.weights[7].shape)\n",
        "print('Kernel:', model_l2.weights[7])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers name: dense_18/kernel:0\n",
            "Layers kernel shape: (32, 16)\n",
            "Kernel: tf.Tensor(\n",
            "[ 0.14804125  0.29042384 -0.18226197  0.1758408  -0.04936292 -0.17692558\n",
            " -0.01929512  0.2996297   0.29312304 -0.17358461 -0.01360136  0.04342064\n",
            " -0.12140647  0.1900244  -0.0506347  -0.14109255], shape=(16,), dtype=float32)\n",
            "\n",
            "Layers name: dense_18/bias:0\n",
            "Layers kernel shape: (16,)\n",
            "Kernel: <tf.Variable 'dense_18/bias:0' shape=(16,) dtype=float32, numpy=\n",
            "array([-1.8425977e-02,  5.2768212e-02,  5.6730969e-05,  3.5121836e-02,\n",
            "        1.7354164e-02,  7.5505972e-02, -3.6220703e-02, -3.2940574e-03,\n",
            "       -5.2755732e-02,  5.3901445e-02, -2.4427719e-02,  3.3735432e-02,\n",
            "       -1.6804133e-02, -5.1381599e-02,  2.4080297e-02,  4.1840546e-02],\n",
            "      dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jIAi_Keg5cX",
        "outputId": "ea44c832-86da-40e7-8014-58cbb34bb83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Layers name:', model_l1.weights[6].name)\n",
        "print('Layers kernel shape:', model_l1.weights[6].shape)\n",
        "print('Kernel:', model_l1.weights[6][0], end = '\\n\\n')\n",
        "print('Layers name:', model_l1.weights[7].name)\n",
        "print('Layers kernel shape:', model_l1.weights[7].shape)\n",
        "print('Kernel:', model_l1.weights[7])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers name: dense_13/kernel:0\n",
            "Layers kernel shape: (32, 16)\n",
            "Kernel: tf.Tensor(\n",
            "[ 1.02006085e-01  2.77427763e-01 -1.39439702e-01  2.53699601e-01\n",
            " -6.17238833e-03 -1.42593503e-01  7.64032120e-06  2.72723049e-01\n",
            "  2.68889129e-01 -1.29749551e-01  8.22974073e-07  3.66491645e-06\n",
            " -1.14774384e-01  8.65984783e-02 -6.85067243e-06 -9.62442011e-02], shape=(16,), dtype=float32)\n",
            "\n",
            "Layers name: dense_13/bias:0\n",
            "Layers kernel shape: (16,)\n",
            "Kernel: <tf.Variable 'dense_13/bias:0' shape=(16,) dtype=float32, numpy=\n",
            "array([-2.04828621e-06,  2.09852333e-05,  7.94861080e-06,  1.05014466e-01,\n",
            "       -3.65000560e-05,  1.04609013e-01,  6.97902814e-02,  2.90683147e-06,\n",
            "        5.94242960e-02,  9.35668573e-02,  7.61114759e-03,  1.61256830e-04,\n",
            "        4.09884099e-03, -7.17126604e-05,  4.52472921e-03, -1.03492803e-05],\n",
            "      dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsIOsGYNU7K3",
        "outputId": "ecf66b8a-bb49-4158-f230-1e36564ab667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Sum of the values of the weights without regularization:', sum(abs(model.weights[6][0])).numpy() + sum(abs(model.weights[7][0])).numpy())\n",
        "print('Sum of the values of the weights with regularization l2:', sum(abs(model_l2.weights[6][0])).numpy() + sum(abs(model_l2.weights[7][0])).numpy())\n",
        "print('Sum of the values of the weights with regularization l1:', sum(abs(model_l1.weights[6][0])).numpy() + sum(abs(model_l1.weights[7][0])).numpy())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the values of the weights without regularization: 2.7922049\n",
            "Sum of the values of the weights with regularization l2: 2.3870947\n",
            "Sum of the values of the weights with regularization l1: 1.8903388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18VBzM17Kuic"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "[Dropout](https://keras.io/api/layers/regularization_layers/dropout/) is a technique where randomly selected neurons are ignored during training. They are â€œdropped-outâ€ randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/proxy/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=\"60%\" />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Cv8TZsanpv"
      },
      "source": [
        "```python\n",
        "from keras.layers import Dropout\n",
        "\n",
        "Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtn-ho_4bANL"
      },
      "source": [
        "* `rate`: Float between 0 and 1. Fraction of the input units to drop\n",
        "\n",
        "* `noise_shape`: 1D integer tensor representing the shape of the binary dropout mask that will be multiplied with the input. For instance, if your inputs have shape (batch_size, timesteps, features) and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features)\n",
        "\n",
        "* `seed`: A Python integer to use as random seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9FArszCLh6G",
        "outputId": "5adf43e0-8021-4e84-9b0a-49e39fc1de90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "initializer = tf.keras.initializers.GlorotUniform(seed=1234)\n",
        "\n",
        "\n",
        "model_d = Sequential()\n",
        "model_d.add(Dense(512, input_shape=(dims,), activation = \"relu\", kernel_initializer=initializer))\n",
        "model_d.add(Dense(256, activation = \"relu\", kernel_initializer=initializer))\n",
        "model_d.add(Dropout(0.2))\n",
        "model_d.add(Dense(32, activation = \"relu\", kernel_initializer=initializer))\n",
        "model_d.add(Dropout(0.2))\n",
        "model_d.add(Dense(16, activation = \"relu\", kernel_initializer=initializer))\n",
        "model_d.add(Dropout(0.2))\n",
        "model_d.add(Dense(nb_classes, activation = \"softmax\", kernel_initializer=initializer))\n",
        "\n",
        "\n",
        "model_d.compile(optimizer=SGD(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5t8yqntMsZY",
        "outputId": "b701404f-2215-4576-9551-202ade945ca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_epochs =20\n",
        "network_history = model_d.fit(X_train, Y_train, batch_size=128, \n",
        "                            epochs=n_epochs, verbose=2, validation_data=(X_val, Y_val))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "352/352 - 2s - loss: 2.2579 - accuracy: 0.1688 - val_loss: 2.1569 - val_accuracy: 0.3686\n",
            "Epoch 2/20\n",
            "352/352 - 1s - loss: 2.1486 - accuracy: 0.2674 - val_loss: 2.0326 - val_accuracy: 0.4142\n",
            "Epoch 3/20\n",
            "352/352 - 1s - loss: 2.0484 - accuracy: 0.3187 - val_loss: 1.9145 - val_accuracy: 0.4390\n",
            "Epoch 4/20\n",
            "352/352 - 1s - loss: 1.9495 - accuracy: 0.3579 - val_loss: 1.7877 - val_accuracy: 0.4685\n",
            "Epoch 5/20\n",
            "352/352 - 1s - loss: 1.8486 - accuracy: 0.3850 - val_loss: 1.6645 - val_accuracy: 0.5012\n",
            "Epoch 6/20\n",
            "352/352 - 1s - loss: 1.7557 - accuracy: 0.4064 - val_loss: 1.5477 - val_accuracy: 0.5287\n",
            "Epoch 7/20\n",
            "352/352 - 1s - loss: 1.6661 - accuracy: 0.4297 - val_loss: 1.4454 - val_accuracy: 0.5494\n",
            "Epoch 8/20\n",
            "352/352 - 1s - loss: 1.5897 - accuracy: 0.4443 - val_loss: 1.3486 - val_accuracy: 0.5724\n",
            "Epoch 9/20\n",
            "352/352 - 1s - loss: 1.5185 - accuracy: 0.4613 - val_loss: 1.2650 - val_accuracy: 0.5989\n",
            "Epoch 10/20\n",
            "352/352 - 1s - loss: 1.4598 - accuracy: 0.4822 - val_loss: 1.1949 - val_accuracy: 0.6317\n",
            "Epoch 11/20\n",
            "352/352 - 1s - loss: 1.4013 - accuracy: 0.5007 - val_loss: 1.1335 - val_accuracy: 0.6509\n",
            "Epoch 12/20\n",
            "352/352 - 1s - loss: 1.3566 - accuracy: 0.5158 - val_loss: 1.0824 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "352/352 - 1s - loss: 1.3183 - accuracy: 0.5285 - val_loss: 1.0373 - val_accuracy: 0.6781\n",
            "Epoch 14/20\n",
            "352/352 - 1s - loss: 1.2799 - accuracy: 0.5432 - val_loss: 0.9987 - val_accuracy: 0.6859\n",
            "Epoch 15/20\n",
            "352/352 - 1s - loss: 1.2391 - accuracy: 0.5570 - val_loss: 0.9621 - val_accuracy: 0.6917\n",
            "Epoch 16/20\n",
            "352/352 - 1s - loss: 1.2129 - accuracy: 0.5706 - val_loss: 0.9332 - val_accuracy: 0.7004\n",
            "Epoch 17/20\n",
            "352/352 - 1s - loss: 1.1819 - accuracy: 0.5767 - val_loss: 0.9085 - val_accuracy: 0.7044\n",
            "Epoch 18/20\n",
            "352/352 - 2s - loss: 1.1642 - accuracy: 0.5827 - val_loss: 0.8873 - val_accuracy: 0.7097\n",
            "Epoch 19/20\n",
            "352/352 - 1s - loss: 1.1384 - accuracy: 0.5902 - val_loss: 0.8677 - val_accuracy: 0.7139\n",
            "Epoch 20/20\n",
            "352/352 - 1s - loss: 1.1217 - accuracy: 0.5963 - val_loss: 0.8509 - val_accuracy: 0.7195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiWhORpQWCV7"
      },
      "source": [
        "# Early Stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DIdGPsaVlNe"
      },
      "source": [
        "<pre>To avoid overfitting, we will first split out data to training set and test set and test out model on the test set.\n",
        "Next: we will use two of keras's callbacks <b>EarlyStopping</b> and <b>ModelCheckpoint</b></pre>\n",
        "\n",
        "See also https://keras.io/api/callbacks/\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcaPPk0mVoU4"
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snjpMHYVVpn_",
        "outputId": "30ec525f-033f-4bd2-fc35-51506081a65b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fBestModel = 'best_model.h5' \n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, min_delta = 0.1, verbose=1) \n",
        "best_model = ModelCheckpoint(fBestModel, verbose=0, save_best_only=True)\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs=n_epochs, \n",
        "          batch_size=batch_size, verbose=True, callbacks=[best_model, early_stop]) "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6003 - accuracy: 0.7989 - val_loss: 0.5977 - val_accuracy: 0.7987\n",
            "Epoch 2/20\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5895 - accuracy: 0.8040 - val_loss: 0.5885 - val_accuracy: 0.8003\n",
            "Epoch 3/20\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 0.5796 - accuracy: 0.8067 - val_loss: 0.5810 - val_accuracy: 0.8031\n",
            "Epoch 00003: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38691e0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}